
\chapter{高エネルギー実験における統計処理}
\section{Likelihood}
私達が興味のあるパラメータは（究極的には）信号事象の数に相当する信号強度$\mu$である。
自然界では既に$\mu$は定まった値を持っており、それを人間が知らないだけである。
そのため実験データが得られる確率は
\begin{equation}
P(\rm{data}|\mu)
\end{equation}
と表すことができる。
実験屋が持っている情報は実験データ（とシミュレーションサンプル）であり、データから確率密度関数を求める必要がある。
これがLikelihoodの意味するところである。
\begin{equation}
L(\mu)
\end{equation}

Likelihood 関数を用いると、信号強度$\mu$の推定も最大尤度法（Maximum likelihood; ML）を用いることで可能となる。
慣習的に推定量はハット記号で表し

\begin{equation}
\hat{\mu} = arg max L(\mu)
\end{equation}

と信号強度を推定することができる。
統計量が増加すると $\hat{\mu}\to\mu^{\rm{truth}}$ に近づく。

\subsection{Likelihoodを計算する}
実際の実験では例えば質量の分布（であったり、$p_T$、$E$であったり）のヒストグラムを計算して、
そこに背景事象とデータとの間に統計的に優位な乖離があるかどうかを判別することになる。つまり、

\begin{itemize}
  \item $H_0$：（この世の中には新物理などなく）データと背景事象は一致している
  \item $H_1$：（この世の中に新物理はある！）データと背景事象には何らかの乖離が生じている
\end{itemize}

とする2つの仮説を検討する、仮説検定の議論に持ち込むこととなる。
このときに Neyman-Pearsonの補題（検定量としてLikelihood ratioを用いるのが最も性能が良い）によると、
2つの仮説に基づいたLikelihood funcitonを計算して、それらの比を検定量とした仮説検定を行うことになる。
ヒストグラムに基づいたLikelihoodの計算方法には二種類ある。


\section{Likelihoodの使い方}

ヒストグラムさえ作ることができれば、あとは何らかのツール（もしくは手計算？）でlikelihoodを計算することができる。
計算したlikelihoodは主に3つの使い方が想定されている。

\subsection{Maximum likelihood parameter estimation}
\subsection{Frequentist confidence interval}
\subsection{Beysian credible interval}

\section{Profile likelihood}

あるビン$i$に期待される事象数は、

\begin{equation}
E(n_i) = \mu s_i + b_i
\end{equation}

で表される。$s_i$はそのビンに信号事象が何イベント存在するかを表しており、$b_i$は背景事象が何イベントあるかを表している。
よって$i$ビンに$n_i$事象観測される確率はポワソン分布を用いると

\begin{equation}
\mathcal{P} = \frac{(\mu s_i+b_i)^{n_i}}{n_i!}e^{-(\mu s_i+b_i)}
\end{equation}

と表される。全ビンに対して積を取るとLikelihood functionが定義でき

\begin{equation}
L(\mu)=\prod_{i\in bins} \frac{(\mu s_i+b_i)^{n_i}}{n_i!}e^{-(\mu s_i+b_i)}
\end{equation}

と表される。これが最も単純な形のLikelihood functionであり、$\mu$にのみ依存している。
これは信号事象も背景事象も完全に$100\%$その性質が分かっている実験（現実的にはありえないが）でのみ使用できるlikelihood関数である。\\

もちろん実際には$s_i$や$b_i$は系統誤差の影響（規格化定数や分布の形等の影響、実験家がコントロールできない影響）を受けるため、それらを表すパラメーター（nuisance parameter）として$\bm{\theta}$を用いて、

\begin{equation}
s_i \to s_i(\bm{\theta}),~~b_i\to b_i(\bm{\theta})
\end{equation}

と定義し直すと、likelihood は

\begin{equation}
L(\mu,\bm{\theta})=\prod_{i\in bins} \frac{(\mu s_i(\bm{\theta})+b_i(\bm{\theta}))^{n_i}}{n_i!}e^{-(\mu s_i(\bm{\theta})+b_i(\bm{\theta}))}
\end{equation}

と書き直せる（式の形としては何も変わっていないが）。
この様に、真に興味のある信号強度$\mu$以外のパラメーター（nuisance parameters;NPs）に依存させた likelihood を profile likelihood と呼ぶ。

\subsection{likelihood ratio}
検定量として profile likelihood を用いた尤度比を考える。

\begin{equation}
\lambda(\mu)=\frac{L(\mu,\hat{\hat{\bm{\theta}}})}{L(\hat{\mu},\hat{\bm{\theta}})}
\end{equation}

分子はある$\mu$の値に対してlikelihoodを最大にするNPの値$\hat{\hat{\bm{\theta}}}$を求めたlikelihoodである（confitional maximum-likelihood）。
また分母は全てのパラメーターをスキャンしてlikelihoodを最大にする値$\hat{\mu},~~\hat{\bm{\theta}}$を求めたlikelihoodである（unconditional maximum-likelihood）。
ゆえに定義から

\begin{equation}
0 < \lambda < 1
\end{equation}

の範囲を取る。


\subsection{系統誤差の扱い}
系統誤差は基本的には全く値のわからないものであり、別の実験ないし作業から求める必要がある。
つまり何らかの分布を使って「constrain」する必要がある。
Profile likelihoodは、系統誤差（systematics uncertainties）をlikelihood関数の中に含めることができる。
系統誤差は "constrained" nuisance parameter として式に含める。

\begin{equation}
L(n,\theta^0|\mu,\theta) = \prod_{i\in bins} \mathcal{P}(n_i|\mu \times S_i(\theta)+B(\theta)) \times \prod_{j\in syst} \mathcal{G}(\theta_j^0|\theta_j,\Delta \theta)
\end{equation}

ここで系統誤差は（慣習的に）平均値$\theta^0=0$、分散$\Delta \theta=1$の正規ガウス分布に従うものとされる。
系統誤差の影響とは、あるビン$i$に対して$+1$〜$-1$の値を取らせたときの影響を言う。

系統誤差がNuisance parameterとして尤度関数に含まれたように、
その他のパラメータも尤度関数に「free parameter」として含めることができる\footnote{free parameterとは、と思うかもしれないが値が実験から決めない変量のこと。例えば$\mu$はfree parameterで、尤度関数を最大にする値を推定値として取るという点で、$\mu$もfree parameterである。}。
この nuisance parameter を「Normalizatoin factors（NF）」と呼び、

\begin{equation}
B(\theta,k)=kB(\theta)
\end{equation}

の様に表現することができる（$\mu S(\theta)$と同じ発想）。

\subsection{Fit}

もう一度系統誤差を含めたprofile likelihoodを眺めてみる。

\begin{equation}
L(n,\theta^0|\mu,\theta) = \prod_{i\in bins} \mathcal{P}(n_i|\mu \times S_i(\theta)+B(\theta)) \times \prod_{j\in syst} \mathcal{G}(\theta_j^0|\theta_j,\Delta \theta)
\end{equation}

このlikelihoodは$L(\bm{n},\bm{\theta}^0|\mu,\bm{\theta})$から分かるように、ある信号強度である系統誤差の値をとっている時に、データセット$\bm{n}$、系統誤差$\bm{\theta}^0$の値を取っている関数である。
事前に分かっているのはデータセット$\bm{n}$、系統誤差$\bm{\theta}^0$である\footnote{繰り返しになるが、慣習的にconstrain termのガウス分布は正規化されているので、$\theta^0=0$、$\Delta \theta=1$を意味している。そのため$\mathcal{G}(0|\theta,1)$として見ても良い。}。

maximum-likelihood estimationでパラメータ推定をした際には、
$(\mu,\theta_1,...,\theta_N )$の複数セットの推定量を計算することになる。

通常のlikelihoodは$\mu$に対する関数だったので、$\mu$をスキャンしていき尤度関数が最大値を取るところを見つければよかった。言い換えると一次元の関数の最大値を見つける問題に相当する。
対してProfile likilihoodは、nuisance parameterとして複数のfree parameterに依存しているので、
N次元の関数となっている。


\subsection{Likelihood ratio}
profile likelihood はこれまで見てきたようにNP（系統誤差、規格化定数etc）を含んでいる。
例えばある仮説（つまり$\mu$の値を何かに固定する、ex. $H_0$）を選んだ時に、どのNPの値を使えばよいのだろうか？
データに選ばせよう、というのがProfileの哲学である。

\begin{equation}
t_{\mu_0} =  -2 \ln\frac{L(\mu=\mu_0,\hat{\hat{\theta}})}{L(\hat{\mu},\hat{\theta})}
\end{equation}

を Profile likelihood ratio（PLR）と呼ぶ。

\begin{itemize}
  \item $\hat{\hat{\theta}}$は $\mu=\mu_0$に対するbest-fit（conditional MLE）
  \item $\hat{\theta}$はoverall （global）な best-fit (unconditional MLE)
\end{itemize}

Wilk's theoremによると、PLRは$\chi^2$分布に従うとされる。


\chapter{Asimov data}

Likelihood ratioから計算した検定量（test statistics）は次の形をしていた。
\begin{equation}
  p_\mu = \int_{q_{\mu,\mathrm{obs}}}^\infty f(q_\mu|\mu)dq_\mu
\end{equation}
検定量のsampling distributionを知る必要がある。
上限値の設定のためには$f(q_\mu|\mu)$のがどのような分布になるかを事前に知っておく必要がある。
